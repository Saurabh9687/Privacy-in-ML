{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FV6fMOLB0J3E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import truncnorm\n",
        "# np.random.seed(200)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/nursery/nursery.data\",names=[\"parents\",\"has_nurs\",\"form\",\"children\",\"housing\",\"finance\",\"social\",\"health\",\"Class\"])"
      ],
      "metadata": {
        "id": "9xVNo6TDwoN7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df.sample(frac=0.8,random_state=200)\n",
        "test_df = df.drop(train_df.index)"
      ],
      "metadata": {
        "id": "hppvQJPs0VFJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = train_df['Class']\n",
        "train_X = train_df.drop('Class',axis=1)\n",
        "test_y = test_df['Class']\n",
        "test_X = test_df.drop('Class',axis=1)"
      ],
      "metadata": {
        "id": "_k6rMK831WSH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = train_X.columns\n",
        "num_cols = train_X._get_numeric_data().columns\n",
        "num_count = len(num_cols)\n",
        "cat_cols = list(set(cols) - set(num_cols))\n",
        "cat_count = len(cat_cols)\n",
        "print(\"number of numerical attributes of Dataset = \",num_count ,\"\\nnumber of categorical attributes of Dataset = \",cat_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mXXgUMqV1ZLJ",
        "outputId": "1d60c27f-0ca9-4f3a-ad35-94ed13ba3edd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of numerical attributes of Dataset =  0 \n",
            "number of categorical attributes of Dataset =  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = list(df.columns)\n",
        "\n",
        "unique_values_arr = []\n",
        "for i in column_names :\n",
        "  unique_values = df[i].unique()\n",
        "  unique_values_arr.append(unique_values)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "unique_values_arr_y = unique_values_arr[column_names.index('Class')]\n",
        "unique_values_arr_X = np.delete(unique_values_arr,column_names.index('Class'),axis=0)"
      ],
      "metadata": {
        "id": "e8fA5Hl41fe2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_names_X = list(train_X.columns)"
      ],
      "metadata": {
        "id": "DuyyF9TB1tZ9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_unique_values = 0\n",
        "for i in column_names_X :\n",
        "  unique_values = df[i].unique()\n",
        "  if len(unique_values) >= max_unique_values  :\n",
        "    max_unique_values  = len(unique_values)"
      ],
      "metadata": {
        "id": "3VxurJ6P1wTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = train_df.groupby('Class')"
      ],
      "metadata": {
        "id": "PNg_35vq1yTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_Class =  train_df['Class'].value_counts()"
      ],
      "metadata": {
        "id": "Y6diI47L100_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "order = unique_values_arr_y\n",
        "count_y = count_Class.reindex(order)"
      ],
      "metadata": {
        "id": "7AEoScUw124V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Accuracy_NB(epsilon):\n",
        "  prob_cond_num = [[[0.0 for _ in range(len(unique_values_arr_y))] for _ in range(max_unique_values )] for _ in range(len(column_names_X))]\n",
        "  for col in column_names_X:\n",
        "    if df[col].dtype == 'object':\n",
        "      s = 1\n",
        "      for col in column_names_X:\n",
        "        if train_df[col].dtype == 'object':\n",
        "          for i in range(len(unique_values_arr_X[column_names_X.index(col)])):\n",
        "            for k in range(len(unique_values_arr_y)):\n",
        "              count = len(train_df[(train_df[col] == unique_values_arr_X[column_names_X.index(col)][i]) & (train_df['Class'] == unique_values_arr_y[k])])\n",
        "              count = np.random.laplace(count, s/epsilon)\n",
        "              count = max(count,0)\n",
        "              prob = count/(count_y[unique_values_arr_y[k]])\n",
        "              prob_cond_num[column_names_X.index(col)][i][np.where(unique_values_arr_y == unique_values_arr_y[k])[0][0]] = prob\n",
        "    else:\n",
        "      for i in unique_values_arr_y :\n",
        "        df_class = grouped.get_group(i).drop('Class',axis=1)\n",
        "        \n",
        "        u = df_class[col].max()\n",
        "        l = df_class[col].min()\n",
        "        n = len(df_class)\n",
        "\n",
        "        mean = df_class[col].mean()\n",
        "        sensitivity_mean = (u-l)/(n+1)\n",
        "        sf_mean = sensitivity_mean/epsilon\n",
        "        std = df_class[col].std()\n",
        "        sensitivity_var = n**0.5* (u-l)/(n+1)\n",
        "        sf_std = sensitivity_var/epsilon\n",
        "        for j in range(len(unique_values_arr_X[column_names_X.index(col)])):\n",
        "          x_1 = unique_values_arr_X[column_names_X.index(col)][j]\n",
        "          x = np.random.laplace(mean,sf_mean)+np.random.laplace(std,sf_std)\n",
        "          prob= 1/np.sqrt(2*np.pi)/std*np.exp(-((x-mean)**2)/2/std**2)\n",
        "          prob_cond_num[column_names.index(col)][j][np.where(unique_values_arr_y == i)[0][0]] = prob\n",
        "  Prior_prob = []\n",
        "  noise_1 = abs(np.random.laplace(0,1))\n",
        "  for Class in unique_values_arr_y:\n",
        "    count_y_1 = count_y[Class] + noise_1\n",
        "    prior = (count_y_1+1)/(len(train_df)+1)\n",
        "    Prior_prob.append(prior)\n",
        "\n",
        "  def Probability_NB(sample_no):\n",
        "    prob_NB = []\n",
        "    for i in range(len(unique_values_arr_y)) :\n",
        "      prob = 1\n",
        "      test_class = test_X.iloc[sample_no]\n",
        "      A = test_class.to_numpy()\n",
        "      att = []\n",
        "      for k in range(len(test_class)):\n",
        "          att.append(test_class[k])\n",
        "          probability_att = prob_cond_num[k][np.where(unique_values_arr_X[k] == A[k])[0][0]][i]\n",
        "          prob = probability_att*prob\n",
        "      prob_NB.append(prob*Prior_prob[i])\n",
        "    return prob_NB.index(max(prob_NB))\n",
        "\n",
        "  test_y_arr = test_y.to_numpy()\n",
        "  Count_p = 0\n",
        "  for i in range(len(test_y)):\n",
        "    if unique_values_arr_y[Probability_NB(i)] == test_y_arr[i]:\n",
        "      Count_p += 1\n",
        "  Accuracy = Count_p/len(test_y)*100\n",
        "  return Accuracy"
      ],
      "metadata": {
        "id": "5l4D7EkCvJhC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Epsilon = [0.01,0.1,1]"
      ],
      "metadata": {
        "id": "iWFQOIyuEmPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Accuracy_arr = [0.0  for _ in range(len(Epsilon))]\n",
        "for i in range(len(Epsilon)):\n",
        "  Accuracy_arr[i] = Accuracy_NB(Epsilon[i])\n",
        "  \n",
        "print(Accuracy_arr)"
      ],
      "metadata": {
        "id": "coQoyMw5Ed7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.gca().invert_xaxis()\n",
        "plt.xscale(\"log\")\n",
        "plt.plot(Epsilon, Accuracy_arr, 'r-')     \n",
        "plt.legend()                             \n",
        "plt.xlabel('Epsilon')                          \n",
        "plt.ylabel('Accuracy')                          \n",
        "plt.title('Nursery dataset: 13K records, 8 attributes and 5 classes')         \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w3X7-Wr3Fj7h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}